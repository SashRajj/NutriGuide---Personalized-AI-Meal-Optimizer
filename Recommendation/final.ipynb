{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-surprise\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x107720110>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /packages/d9/8d/40ac32e703f3808159f9e2b33760cfbd6224cc7783eb663091eddc9581c2/scikit_surprise-1.1.4.tar.gz\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x107721e90>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /packages/d9/8d/40ac32e703f3808159f9e2b33760cfbd6224cc7783eb663091eddc9581c2/scikit_surprise-1.1.4.tar.gz\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x107722a10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /packages/d9/8d/40ac32e703f3808159f9e2b33760cfbd6224cc7783eb663091eddc9581c2/scikit_surprise-1.1.4.tar.gz\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x107723150>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /packages/d9/8d/40ac32e703f3808159f9e2b33760cfbd6224cc7783eb663091eddc9581c2/scikit_surprise-1.1.4.tar.gz\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x107723850>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /packages/d9/8d/40ac32e703f3808159f9e2b33760cfbd6224cc7783eb663091eddc9581c2/scikit_surprise-1.1.4.tar.gz\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not install packages due to an OSError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Max retries exceeded with url: /packages/d9/8d/40ac32e703f3808159f9e2b33760cfbd6224cc7783eb663091eddc9581c2/scikit_surprise-1.1.4.tar.gz (Caused by NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x107722d10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /opt/anaconda3/lib/python3.11/site-packages (0.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbour Recommender:\n",
      "      Meal_Id                                               Name  \\\n",
      "0    meal_id5                         gluten-free christmas cake   \n",
      "1   meal_id47                                       peanut gajak   \n",
      "2  meal_id200                        raspberry and balsamic dome   \n",
      "3  meal_id141                                      morning greed   \n",
      "4  meal_id199                              walnut brownie gujiya   \n",
      "5   meal_id78                               strawberry margarita   \n",
      "6  meal_id171  mavinakayi nellikai chitranna (raw mango &amp;...   \n",
      "\n",
      "        Nutrient Veg_Non                                        description  \\\n",
      "0      vitamin_a     veg  christmas dry fruits (pre-soaked), orange zest...   \n",
      "1  carbohydrates     veg                       jaggery (gur), peanuts, ghee   \n",
      "2      vitamin_a     veg  dark chocolate, butter, sugar, water, egg, egg...   \n",
      "3      vitamin_a     veg  panini bread, mint peas mash, ricotta crumble,...   \n",
      "4      magnesium     veg  walnut brownie, chocolate sauce, chocolate chu...   \n",
      "5      vitamin_c     veg  tequila, triple sec liquor, juice of half lime...   \n",
      "6       chloride     veg  sona masoori rice, raw mango , cashews (crushe...   \n",
      "\n",
      "  Price  \n",
      "0   460  \n",
      "1   230  \n",
      "2   420  \n",
      "3   250  \n",
      "4   425  \n",
      "5   630  \n",
      "6   500  \n",
      "\n",
      "Content Based Recommendation:\n",
      "        Meal_Id                           Name Nutrient  Veg_Non  \\\n",
      "363  meal_id251  steam bunny chicken bao hindi     iron  non-veg   \n",
      "139  meal_id109         chicken quinoa biryani     iron  non-veg   \n",
      "296  meal_id116    pan seared thigh of chicken     iron  non-veg   \n",
      "157   meal_id44        steam bunny chicken bao     iron  non-veg   \n",
      "69    meal_id57           dahi lasooni chicken     iron  non-veg   \n",
      "154  meal_id123       thai style chicken tikka     iron  non-veg   \n",
      "152  meal_id121  methi malai cranberry chicken     iron  non-veg   \n",
      "151  meal_id120     microwave tandoori chicken     iron  non-veg   \n",
      "150  meal_id119             chicken dong style     iron  non-veg   \n",
      "146  meal_id115                 chicken palwal     iron  non-veg   \n",
      "\n",
      "                                           description  Price  \n",
      "363  बन्स, मैदा, ड्राई यीस्ट, चीनी, नमक , गर्म पानी...    570  \n",
      "139  onions, tomato, green chillies(slit open), gin...    605  \n",
      "296  चिकन थाई, नमक, कालीमिर्च, नींबू, फ्रेश थाइम, ब...    625  \n",
      "157  बन्स, मैदा, ड्राई यीस्ट, चीनी, नमक , गर्म पानी...    435  \n",
      "69   चिकन (बोनलेस क्यूब्स साइज), चीज, लहसुन, अदरक ल...    335  \n",
      "154  चिकन थाईज़, थाई अदरक, लेमन लीव्ज़, लेमनग्रास, ...    380  \n",
      "152  चिकन (बड़े टुकड़ों में कटा हुआ), नमक, क्रेनबेर...    615  \n",
      "151  चिकन( टुकड़ों में कटा हुआ), लहसुन का पेस्ट, अद...    305  \n",
      "150  तेल, चिकन ब्रेस्ट, लहसुन, अदरक, टोमैटो कैचअप, ...    600  \n",
      "146  चिकन, प्याज, टमाटर, हरी मिर्च, जीरा पाउडर, धनि...    390  \n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surprise'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 191\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m#SVD Recommender\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurprise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, Reader\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurprise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVD\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'surprise'"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "#K Nearest Neighbor\n",
    "class Recommender:\n",
    "    \n",
    "    def __init__(self,profiles,recent_activity,dataset):\n",
    "        self.df = dataset\n",
    "        self.profiles = profiles\n",
    "        self.recent_activity = recent_activity\n",
    "    \n",
    "    def get_features(self,dataframe):\n",
    "        #getting dummies of dataset\n",
    "        nutrient_dummies = dataframe.Nutrient.str.get_dummies()\n",
    "        disease_dummies = dataframe.Disease.str.get_dummies(sep=' ')\n",
    "        diet_dummies = dataframe.Diet.str.get_dummies(sep=' ')\n",
    "        feature_df = pd.concat([nutrient_dummies,disease_dummies,diet_dummies],axis=1)\n",
    "     \n",
    "        return feature_df\n",
    "    \n",
    "    def find_neighbors(self,dataframe,features,k):\n",
    "        features_df = self.get_features(dataframe)\n",
    "        total_features = features_df.columns  \n",
    "        d = dict()\n",
    "        for i in total_features:\n",
    "            d[i]= 0\n",
    "        for i in features:\n",
    "            d[i] = 1\n",
    "        final_input = list(d.values())\n",
    "        \n",
    "        similar_neighbors = self.k_neighbor([final_input],features_df,dataframe,k)\n",
    "        return similar_neighbors\n",
    "    \n",
    "    def k_neighbor(self,inputs,feature_df,dataframe,k):\n",
    "        \n",
    "        #initializing model with k neighbors\n",
    "        model = NearestNeighbors(n_neighbors=k,algorithm='ball_tree')\n",
    "        \n",
    "        # fitting model with dataset features\n",
    "        model.fit(feature_df)\n",
    "        \n",
    "        df_results = pd.DataFrame(columns=list(dataframe.columns))\n",
    "        \n",
    "        # getting distance and indices for k nearest neighbor\n",
    "        distnaces , indices = model.kneighbors(inputs)\n",
    "\n",
    "        for i in list(indices):\n",
    "            df_results = pd.concat([df_results, pd.DataFrame(dataframe.loc[i])])\n",
    "\n",
    "        df_results = df_results.reset_index(drop=True)\n",
    "        return df_results\n",
    "    \n",
    "    def user_based(self,features,user_id):\n",
    "       \n",
    "        similar_users = self.find_neighbors(self.profiles,features,10)\n",
    "        users = list(similar_users.User_Id)\n",
    "    \n",
    "        results = self.recent_activity[self.recent_activity.User_Id.isin(users)] #taking acitivies\n",
    "   \n",
    "        results = results[results['User_Id']!=user_id] # selecting those which are not reviewed by user\n",
    " \n",
    "        meals = list(results.Meal_Id.unique())\n",
    "      \n",
    "        results = self.df[self.df.Meal_Id.isin(meals)]\n",
    "    \n",
    "        results = results.filter(['Meal_Id','Name','Nutrient','Veg_Non','description','Price','Review'])\n",
    "\n",
    "        results = results.drop_duplicates(subset=['Name'])\n",
    "        results = results.reset_index(drop=True)\n",
    "        return results\n",
    "        \n",
    "    def recent_activity_based(self,user_id):\n",
    "        recent_df = self.recent_activity[self.recent_activity['User_Id']==user_id]\n",
    "        meal_ids = list(recent_df.Meal_Id.unique())\n",
    "        recent_data = self.df[self.df.Meal_Id.isin(meal_ids)][['Nutrient','catagory','Disease','Diet']].reset_index(drop=True)\n",
    "\n",
    "        disease = []\n",
    "        diet = []\n",
    "        for i in range(recent_data.shape[0]):\n",
    "            for j in recent_data.loc[i,'Disease'].split():\n",
    "                disease.append(j)\n",
    "        for i in range(recent_data.shape[0]):\n",
    "            for j in recent_data.loc[i,'Diet'].split():\n",
    "                diet.append(j)\n",
    "                \n",
    "        value_counts = recent_data.Nutrient.value_counts()\n",
    "        m = recent_data.Nutrient.value_counts().mean()\n",
    "        features = list(value_counts[recent_data.Nutrient.value_counts()>m].index)\n",
    "        a = dict(Counter(disease))\n",
    "        \n",
    "        m = np.mean(list(a.values()))\n",
    "        for i in a.items():\n",
    "            if i[1]>m:\n",
    "                features.append(i[0])\n",
    "        a = dict(Counter(diet))\n",
    "        m = np.mean(list(a.values()))\n",
    "        for i in a.items():\n",
    "            if i[1]>m:\n",
    "                features.append(i[0])\n",
    "                \n",
    "        similar_neighbors = self.find_neighbors(self.df,features,10)\n",
    "        return similar_neighbors.filter(['Meal_Id','Name','Nutrient','Veg_Non','description','Price','Review'])\n",
    "        \n",
    "    def recommend(self,user_id):\n",
    "        #finding user's profile features by id\n",
    "        profile = self.profiles[self.profiles['User_Id']==user_id]\n",
    "        features = []\n",
    "        features.append(profile['Nutrient'].values[0])\n",
    "        features.extend(profile['Disease'].values[0].split())\n",
    "        features.extend(profile['Diet'].values[0].split())\n",
    "        df1 = self.user_based(features,user_id)\n",
    " \n",
    "        df2 = self.recent_activity_based(user_id)\n",
    "        df = pd.concat([df1,df2])\n",
    "      \n",
    "        df = df.drop_duplicates('description').reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "# %%\n",
    "print(\"Nearest Neighbour Recommender:\")\n",
    "user_id = 'User_44'  # user id of current user\n",
    "\n",
    "profiles = pd.read_csv('../Data processing/user_Profiles.csv') # profiles of all users\n",
    "recent_activity = pd.read_csv('../Data processing/recent_activity.csv') # recent activities of current user (meals liked,rated,searched,Purchased)\n",
    "dataset = pd.read_csv('../Data processing/dataset.csv') # main dataset\n",
    "\n",
    "\n",
    "ob = Recommender(profiles,recent_activity,dataset)\n",
    "result = ob.recommend(user_id)\n",
    "print(result)\n",
    "\n",
    "\n",
    "#Content Based Recommendation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "class ContentBasedRecommender:\n",
    "    def __init__(self, dataset, profiles):\n",
    "        self.df = dataset\n",
    "        self.profile = profiles\n",
    "        self.tfidf_matrix, self.tfidf = self.generate_tfidf_matrix()\n",
    "    \n",
    "    def generate_tfidf_matrix(self):\n",
    "        # Create a TF-IDF Vectorizer\n",
    "        tfidf = TfidfVectorizer(stop_words='english')\n",
    "        \n",
    "        # Fill NaN values in 'Nutrient', 'Disease', 'Diet' columns in the dataset\n",
    "        self.df['Nutrient'] = self.df['Nutrient'].fillna('')\n",
    "        self.df['Disease'] = self.df['Disease'].fillna('')\n",
    "        self.df['Diet'] = self.df['Diet'].fillna('')\n",
    "        \n",
    "        # Combine text features into a single column for the dataset\n",
    "        self.df['combined_features'] = self.df['Nutrient'] + ' ' + self.df['Disease'] + ' ' + self.df['Diet']\n",
    "        \n",
    "        # Fit and transform the TF-IDF Vectorizer on the dataset\n",
    "        tfidf_matrix = tfidf.fit_transform(self.df['combined_features'])\n",
    "        \n",
    "        return tfidf_matrix, tfidf  # Return both TF-IDF matrix and vectorizer\n",
    "    \n",
    "    def content_based_recommendation(self, user_id, top_n=10):\n",
    "        user_profile = self.profile[self.profile['User_Id'] == user_id]\n",
    "        user_features = user_profile['Nutrient'].values[0] + ' ' + user_profile['Disease'].values[0] + ' ' + user_profile['Diet'].values[0]\n",
    "        user_tfidf_matrix = self.tfidf.transform([user_features])\n",
    "        cosine_sim = linear_kernel(user_tfidf_matrix, self.tfidf_matrix).flatten()\n",
    "        \n",
    "        # Initialize a set to track unique Meal_Id recommendations\n",
    "        unique_meals = set()\n",
    "        recommendations = []\n",
    "        meal_indices = cosine_sim.argsort()[::-1]  # Sort indices in descending order of similarity\n",
    "        \n",
    "        for idx in meal_indices:\n",
    "            meal_id = self.df.at[idx, 'Meal_Id']\n",
    "            if meal_id not in unique_meals:\n",
    "                recommendations.append(self.df.iloc[idx])\n",
    "                unique_meals.add(meal_id)\n",
    "                if len(recommendations) == top_n:\n",
    "                    break\n",
    "        \n",
    "        recommendations = pd.DataFrame(recommendations)\n",
    "        del recommendations['combined_features']\n",
    "        return recommendations[['Meal_Id', 'Name', 'Nutrient', 'Veg_Non', 'description', 'Price']]\n",
    "\n",
    "# Usage\n",
    "print()\n",
    "print(\"Content Based Recommendation:\")\n",
    "user_id = 'User_44'\n",
    "ob = ContentBasedRecommender(dataset, profiles)\n",
    "result = ob.content_based_recommendation(user_id)\n",
    "print(result)\n",
    "\n",
    "\n",
    "#SVD Recommender\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "class SVDRecommender:\n",
    "    def __init__(self, profiles, recent_activity, dataset):\n",
    "        self.df = dataset\n",
    "        self.profiles = profiles\n",
    "        self.recent_activity = recent_activity\n",
    "        self.data = self.prepare_data()\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        # Create a Surprise Dataset\n",
    "        reader = Reader(rating_scale=(1, 5))  # Assuming a rating scale\n",
    "        data = Dataset.load_from_df(self.recent_activity[['User_Id', 'Meal_Id', 'Rated']], reader)\n",
    "        return data\n",
    "    \n",
    "    def svd_recommendation(self, user_id, top_n=10):\n",
    "        trainset = self.data.build_full_trainset()  # Use full data for training\n",
    "\n",
    "        # Define and train the model (SVD)\n",
    "        model = SVD()\n",
    "        model.fit(trainset)\n",
    "\n",
    "        # Get all meal IDs\n",
    "        all_meals = self.df['Meal_Id'].unique()\n",
    "\n",
    "        # Get the meals that the user hasn't interacted with\n",
    "        user_meals = self.recent_activity[self.recent_activity['User_Id'] == user_id]['Meal_Id']\n",
    "        unseen_meals = np.setdiff1d(all_meals, user_meals)\n",
    "\n",
    "        # Predict ratings for the unseen meals\n",
    "        predictions = [model.predict(user_id, meal_id) for meal_id in unseen_meals]\n",
    "\n",
    "        # Sort predictions by estimated ratings in descending order\n",
    "        sorted_predictions = sorted(predictions, key=lambda x: x.est, reverse=True)\n",
    "\n",
    "        # Get top N recommendations\n",
    "        top_recommendations = sorted_predictions[:top_n]\n",
    "\n",
    "        # Format and return top recommendations\n",
    "        top_meal_ids = [pred.iid for pred in top_recommendations]\n",
    "        recommended_meals = self.df[self.df['Meal_Id'].isin(top_meal_ids)]\n",
    "        recommended_meals = recommended_meals.drop_duplicates(subset=['Meal_Id'])\n",
    "        return recommended_meals[['Meal_Id', 'Name', 'Nutrient', 'Veg_Non', 'description', 'Price']]\n",
    "\n",
    "# Usage\n",
    "print()\n",
    "print(\"SVD Recommender:\")\n",
    "user_id = 'User_44'  # User ID of current user\n",
    "\n",
    "profiles = pd.read_csv('../Data processing/user_Profiles.csv')  # Profiles of all users\n",
    "recent_activity = pd.read_csv('../Data processing/recent_activity.csv')  # Recent activities of current user\n",
    "dataset = pd.read_csv('../Data processing/dataset.csv')  # Main dataset\n",
    "\n",
    "svd_ob = SVDRecommender(profiles, recent_activity, dataset)\n",
    "svd_result = svd_ob.svd_recommendation(user_id)\n",
    "print(svd_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
