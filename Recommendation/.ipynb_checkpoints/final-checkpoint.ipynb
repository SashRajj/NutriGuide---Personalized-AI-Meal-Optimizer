{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-surprise in c:\\users\\ngangar2\\appdata\\roaming\\python\\python39\\site-packages (1.1.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.21.5)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tabulate in c:\\programdata\\anaconda3\\lib\\site-packages (0.8.10)\n"
     ]
    }
   ],
   "source": [
    "pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbour Recommender:\n",
      "      Meal_Id                                               Name  \\\n",
      "0    meal_id5                         gluten-free christmas cake   \n",
      "1   meal_id47                                       peanut gajak   \n",
      "2  meal_id199                              walnut brownie gujiya   \n",
      "3  meal_id200                        raspberry and balsamic dome   \n",
      "4  meal_id171  mavinakayi nellikai chitranna (raw mango &amp;...   \n",
      "5  meal_id141                                      morning greed   \n",
      "6   meal_id78                               strawberry margarita   \n",
      "\n",
      "        Nutrient Veg_Non                                        description  \\\n",
      "0      vitamin_a     veg  christmas dry fruits (pre-soaked), orange zest...   \n",
      "1  carbohydrates     veg                       jaggery (gur), peanuts, ghee   \n",
      "2      magnesium     veg  walnut brownie, chocolate sauce, chocolate chu...   \n",
      "3      vitamin_a     veg  dark chocolate, butter, sugar, water, egg, egg...   \n",
      "4       chloride     veg  sona masoori rice, raw mango , cashews (crushe...   \n",
      "5      vitamin_a     veg  panini bread, mint peas mash, ricotta crumble,...   \n",
      "6      vitamin_c     veg  tequila, triple sec liquor, juice of half lime...   \n",
      "\n",
      "  Price  \n",
      "0   460  \n",
      "1   610  \n",
      "2   425  \n",
      "3   420  \n",
      "4   500  \n",
      "5   250  \n",
      "6   630  \n",
      "\n",
      "Content Based Recommendation:\n",
      "        Meal_Id                           Name Nutrient  Veg_Non  \\\n",
      "363  meal_id251  steam bunny chicken bao hindi     iron  non-veg   \n",
      "139  meal_id109         chicken quinoa biryani     iron  non-veg   \n",
      "296  meal_id116    pan seared thigh of chicken     iron  non-veg   \n",
      "157   meal_id44        steam bunny chicken bao     iron  non-veg   \n",
      "69    meal_id57           dahi lasooni chicken     iron  non-veg   \n",
      "154  meal_id123       thai style chicken tikka     iron  non-veg   \n",
      "152  meal_id121  methi malai cranberry chicken     iron  non-veg   \n",
      "151  meal_id120     microwave tandoori chicken     iron  non-veg   \n",
      "150  meal_id119             chicken dong style     iron  non-veg   \n",
      "146  meal_id115                 chicken palwal     iron  non-veg   \n",
      "\n",
      "                                           description  Price  \n",
      "363  बन्स, मैदा, ड्राई यीस्ट, चीनी, नमक , गर्म पानी...    570  \n",
      "139  onions, tomato, green chillies(slit open), gin...    605  \n",
      "296  चिकन थाई, नमक, कालीमिर्च, नींबू, फ्रेश थाइम, ब...    625  \n",
      "157  बन्स, मैदा, ड्राई यीस्ट, चीनी, नमक , गर्म पानी...    435  \n",
      "69   चिकन (बोनलेस क्यूब्स साइज), चीज, लहसुन, अदरक ल...    335  \n",
      "154  चिकन थाईज़, थाई अदरक, लेमन लीव्ज़, लेमनग्रास, ...    380  \n",
      "152  चिकन (बड़े टुकड़ों में कटा हुआ), नमक, क्रेनबेर...    615  \n",
      "151  चिकन( टुकड़ों में कटा हुआ), लहसुन का पेस्ट, अद...    305  \n",
      "150  तेल, चिकन ब्रेस्ट, लहसुन, अदरक, टोमैटो कैचअप, ...    600  \n",
      "146  चिकन, प्याज, टमाटर, हरी मिर्च, जीरा पाउडर, धनि...    390  \n",
      "\n",
      "SVD Recommender:\n",
      "        Meal_Id                          Name   Nutrient  Veg_Non  \\\n",
      "0      meal_id1           summer squash salad      fiber      veg   \n",
      "9     meal_id10      broccoli and almond soup  vitamin_c      veg   \n",
      "129  meal_id100           spicy chicken curry       iron  non-veg   \n",
      "130  meal_id101           crispy herb chicken   chloride  non-veg   \n",
      "131  meal_id102                  dahi chicken       iron  non-veg   \n",
      "132  meal_id103      amritsari chicken masala       iron  non-veg   \n",
      "133  meal_id104                chilli chicken   chloride  non-veg   \n",
      "134  meal_id105   oat crusted chicken tenders       iron  non-veg   \n",
      "135  meal_id106  chicken nimbu dhaniya shorba   chloride  non-veg   \n",
      "137  meal_id107           garlic soya chicken       iron  non-veg   \n",
      "\n",
      "                                           description  Price  \n",
      "0    white balsamic vinegar, lemon juice, lemon rin...    565  \n",
      "9    vegetable stock, broccoli, ground almonds (toa...    695  \n",
      "129  oil, ghee, onion paste, garlic paste, ginger p...    600  \n",
      "130  fresh breadcrumbs, parmesan cheese, lemon rind...    315  \n",
      "131  dahi, cumin powder, garlic paste, garam masala...    570  \n",
      "132  chicken, ginger garlic paste, curd, lemon juic...    685  \n",
      "133  boneless chicken, salt, cornflour, black peppe...    620  \n",
      "134  chicken breast (cut into strips), salt, garlic...    465  \n",
      "135  water, chicken (diced)), ginger garlic paste, ...    665  \n",
      "137  chicken thigh/breast (cut crosswise into 1/2-i...    415  \n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "class Recommender:\n",
    "    \n",
    "    def __init__(self,profiles,recent_activity,dataset):\n",
    "        self.df = dataset\n",
    "        self.profiles = profiles\n",
    "        self.recent_activity = recent_activity\n",
    "    \n",
    "    def get_features(self,dataframe):\n",
    "        #getting dummies of dataset\n",
    "        nutrient_dummies = dataframe.Nutrient.str.get_dummies()\n",
    "        disease_dummies = dataframe.Disease.str.get_dummies(sep=' ')\n",
    "        diet_dummies = dataframe.Diet.str.get_dummies(sep=' ')\n",
    "        feature_df = pd.concat([nutrient_dummies,disease_dummies,diet_dummies],axis=1)\n",
    "     \n",
    "        return feature_df\n",
    "    \n",
    "    def find_neighbors(self,dataframe,features,k):\n",
    "        features_df = self.get_features(dataframe)\n",
    "        total_features = features_df.columns  \n",
    "        d = dict()\n",
    "        for i in total_features:\n",
    "            d[i]= 0\n",
    "        for i in features:\n",
    "            d[i] = 1\n",
    "        final_input = list(d.values())\n",
    "        \n",
    "        similar_neighbors = self.k_neighbor([final_input],features_df,dataframe,k)\n",
    "        return similar_neighbors\n",
    "    \n",
    "    def k_neighbor(self,inputs,feature_df,dataframe,k):\n",
    "        \n",
    "        #initializing model with k neighbors\n",
    "        model = NearestNeighbors(n_neighbors=k,algorithm='ball_tree')\n",
    "        \n",
    "        # fitting model with dataset features\n",
    "        model.fit(feature_df)\n",
    "        \n",
    "        df_results = pd.DataFrame(columns=list(dataframe.columns))\n",
    "        \n",
    "        # getting distance and indices for k nearest neighbor\n",
    "        distnaces , indices = model.kneighbors(inputs)\n",
    "\n",
    "        for i in list(indices):\n",
    "            df_results = pd.concat([df_results, pd.DataFrame(dataframe.loc[i])])\n",
    "\n",
    "        df_results = df_results.reset_index(drop=True)\n",
    "        return df_results\n",
    "    \n",
    "    def user_based(self,features,user_id):\n",
    "       \n",
    "        similar_users = self.find_neighbors(self.profiles,features,10)\n",
    "        users = list(similar_users.User_Id)\n",
    "    \n",
    "        results = self.recent_activity[self.recent_activity.User_Id.isin(users)] #taking acitivies\n",
    "   \n",
    "        results = results[results['User_Id']!=user_id] # selecting those which are not reviewed by user\n",
    " \n",
    "        meals = list(results.Meal_Id.unique())\n",
    "      \n",
    "        results = self.df[self.df.Meal_Id.isin(meals)]\n",
    "    \n",
    "        results = results.filter(['Meal_Id','Name','Nutrient','Veg_Non','description','Price','Review'])\n",
    "\n",
    "        results = results.drop_duplicates(subset=['Name'])\n",
    "        results = results.reset_index(drop=True)\n",
    "        return results\n",
    "        \n",
    "    def recent_activity_based(self,user_id):\n",
    "        recent_df = self.recent_activity[self.recent_activity['User_Id']==user_id]\n",
    "        meal_ids = list(recent_df.Meal_Id.unique())\n",
    "        recent_data = self.df[self.df.Meal_Id.isin(meal_ids)][['Nutrient','catagory','Disease','Diet']].reset_index(drop=True)\n",
    "\n",
    "        disease = []\n",
    "        diet = []\n",
    "        for i in range(recent_data.shape[0]):\n",
    "            for j in recent_data.loc[i,'Disease'].split():\n",
    "                disease.append(j)\n",
    "        for i in range(recent_data.shape[0]):\n",
    "            for j in recent_data.loc[i,'Diet'].split():\n",
    "                diet.append(j)\n",
    "                \n",
    "        value_counts = recent_data.Nutrient.value_counts()\n",
    "        m = recent_data.Nutrient.value_counts().mean()\n",
    "        features = list(value_counts[recent_data.Nutrient.value_counts()>m].index)\n",
    "        a = dict(Counter(disease))\n",
    "        \n",
    "        m = np.mean(list(a.values()))\n",
    "        for i in a.items():\n",
    "            if i[1]>m:\n",
    "                features.append(i[0])\n",
    "        a = dict(Counter(diet))\n",
    "        m = np.mean(list(a.values()))\n",
    "        for i in a.items():\n",
    "            if i[1]>m:\n",
    "                features.append(i[0])\n",
    "                \n",
    "        similar_neighbors = self.find_neighbors(self.df,features,10)\n",
    "        return similar_neighbors.filter(['Meal_Id','Name','Nutrient','Veg_Non','description','Price','Review'])\n",
    "        \n",
    "    def recommend(self,user_id):\n",
    "        #finding user's profile features by id\n",
    "        profile = self.profiles[self.profiles['User_Id']==user_id]\n",
    "        features = []\n",
    "        features.append(profile['Nutrient'].values[0])\n",
    "        features.extend(profile['Disease'].values[0].split())\n",
    "        features.extend(profile['Diet'].values[0].split())\n",
    "        df1 = self.user_based(features,user_id)\n",
    " \n",
    "        df2 = self.recent_activity_based(user_id)\n",
    "        df = pd.concat([df1,df2])\n",
    "      \n",
    "        df = df.drop_duplicates('description').reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "# %%\n",
    "print(\"Nearest Neighbour Recommender:\")\n",
    "user_id = 'User_44'  # user id of current user\n",
    "\n",
    "profiles = pd.read_csv('../Data processing/user_Profiles.csv') # profiles of all users\n",
    "recent_activity = pd.read_csv('../Data processing/recent_activity.csv') # recent activities of current user (meals liked,rated,searched,Purchased)\n",
    "dataset = pd.read_csv('../Data processing/dataset.csv') # main dataset\n",
    "\n",
    "\n",
    "ob = Recommender(profiles,recent_activity,dataset)\n",
    "result = ob.recommend(user_id)\n",
    "print(result)\n",
    "\n",
    "\n",
    "\n",
    "'''class UserUserCFRecommender(Recommender):\n",
    "    def user_user_collab_filtering(self, user_id):\n",
    "        # Filter recent activity for the current user\n",
    "        user_activity = self.recent_activity[self.recent_activity['User_Id'] == user_id]\n",
    "        user_meal_ids = user_activity['Meal_Id'].tolist()\n",
    "        user_purchased_meals = user_activity[user_activity['Purchased'] == 1]['Meal_Id'].tolist()\n",
    "        print(user_purchased_meals)\n",
    "        user_purchased = self.df[self.df['Meal_Id'].isin(user_purchased_meals)]\n",
    "        print(user_purchased)\n",
    "\n",
    "        # Filter dataset for meals interacted by the current user\n",
    "        user_meals = self.df[self.df['Meal_Id'].isin(user_meal_ids)]\n",
    "        print(\"Here\")\n",
    "        # Create a pivot table of user interactions (ratings/likes) with meals\n",
    "        #interactions = self.recent_activity.pivot_table(index='User_Id')#user_meals.pivot_table(index='User_Id', columns='Meal_Id', values='Purchased', fill_value=0)\n",
    "        interactions = user_purchased.pivot_table(index='User_Id', columns='Meal_Id', values='Purchased', fill_value=0)\n",
    "\n",
    "        print(len(interactions))\n",
    "        # Calculate cosine similarity between users based on their meal interactions\n",
    "        similarity_matrix = cosine_similarity(interactions)\n",
    "\n",
    "        # Find similar users to the current user\n",
    "        similar_users_indices = np.argsort(similarity_matrix[user_id])[::-1][1:]  # Exclude the user itself\n",
    "\n",
    "        # Gather meals liked by similar users\n",
    "        similar_users_meals = interactions.iloc[similar_users_indices]\n",
    "        recommended_meals = similar_users_meals[similar_users_meals > 0].fillna(0)\n",
    "        recommended_meals = recommended_meals.sum().sort_values(ascending=False)\n",
    "\n",
    "        # Filter recommended meals that the user hasn't interacted with yet\n",
    "        final_recommendations = recommended_meals[~recommended_meals.index.isin(user_meal_ids)].index.tolist()\n",
    "\n",
    "        return self.df[self.df['Meal_Id'].isin(final_recommendations)][['Meal_Id', 'Name', 'Nutrient', 'Veg_Non', 'description', 'Price', 'Review']]\n",
    "'''\n",
    "# Usage:\n",
    "'''user_id = 'User_71'  # user id of current user\n",
    "ob = UserUserCFRecommender(profiles, recent_activity, dataset)\n",
    "result = ob.user_user_collab_filtering(user_id)\n",
    "print(result)'''\n",
    "\n",
    "'''class ItemItemRecommender:\n",
    "    \n",
    "    def __init__(self, dataset, profiles, recent_activity):\n",
    "        self.df = dataset\n",
    "        self.profiles = profiles\n",
    "        self.recent_activity = recent_activity\n",
    "    \n",
    "    def create_item_item_matrix(self):\n",
    "        # Create a multi-hot encoded matrix for the features\n",
    "        features_matrix = self.df.pivot_table(index='Meal_Id', columns='Nutrient', aggfunc='size', fill_value=0)\n",
    "        \n",
    "        # Adding other categorical features using get_dummies\n",
    "        other_features = ['Disease', 'Diet']\n",
    "        for feature in other_features:\n",
    "            dummies = self.df[feature].str.get_dummies(sep=' ')\n",
    "            features_matrix = pd.concat([features_matrix, dummies], axis=1)\n",
    "        \n",
    "        return features_matrix\n",
    "    def create_item_item_matrix(self):\n",
    "        # Create a pivot table with Meal_Id as rows, features as columns, and Review as values\n",
    "        item_item_matrix = self.df.pivot_table(index='Meal_Id', columns='Nutrient', values='Review').fillna(0)\n",
    "        return item_item_matrix\n",
    "    \n",
    "    def find_similar_items(self, meal_id, item_item_matrix, k=5):\n",
    "        # Finding similarity between items based on their reviews\n",
    "        similarities = item_item_matrix.corrwith(item_item_matrix.loc[meal_id], axis=0)\n",
    "        similarities = similarities.sort_values(ascending=False)\n",
    "        \n",
    "        # Exclude the queried meal itself\n",
    "        similarities = similarities.drop(meal_id)\n",
    "        \n",
    "        # Get the top k similar items\n",
    "        similar_items = similarities.head(k)\n",
    "        return similar_items\n",
    "    \n",
    "    def recommend_items(self, user_id, k=10):\n",
    "        # Get meals that the user hasn't interacted with\n",
    "        print(self.profiles.columns)\n",
    "        profile = self.profiles[self.profiles['User_Id'] == user_id]\n",
    "        print(profile)\n",
    "        features = profile.filter(['Nutrient', 'Disease', 'Diet'])\n",
    "        print(features)\n",
    "        similar_items = self.find_similar_items(features)\n",
    "        user_meals = set(self.profiles[self.profiles['User_Id'] == user_id]['Meal_Id'])\n",
    "        print(user_meals)\n",
    "        all_meals = set(self.df['Meal_Id'])\n",
    "        not_interacted = list(all_meals - user_meals)\n",
    "        print(len(not_interacted))\n",
    "        # Create an item-item matrix\n",
    "        item_item_matrix = self.create_item_item_matrix()\n",
    "        \n",
    "        recommended_items = {}\n",
    "        for meal_id in not_interacted:\n",
    "            # Find similar items for each not-interacted meal\n",
    "            similar_items = self.find_similar_items(meal_id, item_item_matrix, k)\n",
    "            \n",
    "            # Store the top k similar items for each meal\n",
    "            recommended_items[meal_id] = list(similar_items.index)\n",
    "            print(recommended_items)\n",
    "        \n",
    "        return recommended_items'''\n",
    "\n",
    "\n",
    "\n",
    "'''class ContentBasedRecommender:\n",
    "    def __init__(self, dataset, profiles):\n",
    "        self.df = dataset\n",
    "        self.profile = profiles\n",
    "        self.tfidf_matrix, self.tfidf = self.generate_tfidf_matrix()\n",
    "    \n",
    "    def generate_tfidf_matrix(self):\n",
    "        # Create a TF-IDF Vectorizer\n",
    "        tfidf = TfidfVectorizer(stop_words='english')\n",
    "        \n",
    "        # Fill NaN values in 'Nutrient', 'Disease', 'Diet' columns in the dataset\n",
    "        self.df['Nutrient'] = self.df['Nutrient'].fillna('')\n",
    "        self.df['Disease'] = self.df['Disease'].fillna('')\n",
    "        self.df['Diet'] = self.df['Diet'].fillna('')\n",
    "        \n",
    "        # Combine text features into a single column for the dataset\n",
    "        self.df['combined_features'] = self.df['Nutrient'] + ' ' + self.df['Disease'] + ' ' + self.df['Diet']\n",
    "        \n",
    "        # Fit and transform the TF-IDF Vectorizer on the dataset\n",
    "        tfidf_matrix = tfidf.fit_transform(self.df['combined_features'])\n",
    "        \n",
    "        return tfidf_matrix, tfidf  # Return both TF-IDF matrix and vectorizer\n",
    "    \n",
    "    def content_based_recommendation(self, user_id, top_n=10):\n",
    "        user_profile = self.profile[self.profile['User_Id'] == user_id]\n",
    "        user_features = user_profile['Nutrient'].values[0] + ' ' + user_profile['Disease'].values[0] + ' ' + user_profile['Diet'].values[0]\n",
    "        \n",
    "        # Calculate TF-IDF for user features using the same Vectorizer\n",
    "        user_tfidf_matrix = self.tfidf.transform([user_features])\n",
    "        \n",
    "        # Calculate cosine similarity between user and meal features\n",
    "        cosine_sim = linear_kernel(user_tfidf_matrix, self.tfidf_matrix).flatten()\n",
    "        \n",
    "        # Get indices of top similar meals\n",
    "        similar_meals_indices = cosine_sim.argsort()[:-top_n-1:-1]\n",
    "        \n",
    "        # Return top recommended meals\n",
    "        recommended_meals = self.df.iloc[similar_meals_indices].reset_index(drop=True)\n",
    "        del recommended_meals['combined_features']\n",
    "        return recommended_meals#[['Meal_Id', 'Name', 'Nutrient', 'Veg_Non', 'description', 'Price', 'Review']]'''\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "class ContentBasedRecommender:\n",
    "    def __init__(self, dataset, profiles):\n",
    "        self.df = dataset\n",
    "        self.profile = profiles\n",
    "        self.tfidf_matrix, self.tfidf = self.generate_tfidf_matrix()\n",
    "    \n",
    "    def generate_tfidf_matrix(self):\n",
    "        # Create a TF-IDF Vectorizer\n",
    "        tfidf = TfidfVectorizer(stop_words='english')\n",
    "        \n",
    "        # Fill NaN values in 'Nutrient', 'Disease', 'Diet' columns in the dataset\n",
    "        self.df['Nutrient'] = self.df['Nutrient'].fillna('')\n",
    "        self.df['Disease'] = self.df['Disease'].fillna('')\n",
    "        self.df['Diet'] = self.df['Diet'].fillna('')\n",
    "        \n",
    "        # Combine text features into a single column for the dataset\n",
    "        self.df['combined_features'] = self.df['Nutrient'] + ' ' + self.df['Disease'] + ' ' + self.df['Diet']\n",
    "        \n",
    "        # Fit and transform the TF-IDF Vectorizer on the dataset\n",
    "        tfidf_matrix = tfidf.fit_transform(self.df['combined_features'])\n",
    "        \n",
    "        return tfidf_matrix, tfidf  # Return both TF-IDF matrix and vectorizer\n",
    "    \n",
    "    '''def content_based_recommendation(self, user_id, top_n=10):\n",
    "        user_profile = self.profile[self.profile['User_Id'] == user_id]\n",
    "        user_features = user_profile['Nutrient'].values[0] + ' ' + user_profile['Disease'].values[0] + ' ' + user_profile['Diet'].values[0]\n",
    "        \n",
    "        # Calculate TF-IDF for user features using the same Vectorizer\n",
    "        user_tfidf_matrix = self.tfidf.transform([user_features])\n",
    "        \n",
    "        # Calculate cosine similarity between user and meal features\n",
    "        cosine_sim = linear_kernel(user_tfidf_matrix, self.tfidf_matrix).flatten()\n",
    "        \n",
    "        # Get indices of top similar meals\n",
    "        similar_meals_indices = cosine_sim.argsort()[:-top_n-1:-1]\n",
    "        \n",
    "        # Retrieve recommended meals\n",
    "        recommended_meals = self.df.iloc[similar_meals_indices].reset_index(drop=True)\n",
    "        \n",
    "        # Remove duplicates based on 'Meal_Id'\n",
    "        recommended_meals = recommended_meals.drop_duplicates(subset=['Meal_Id'])\n",
    "        del recommended_meals['combined_features']\n",
    "        return recommended_meals#[['Meal_Id', 'Name', 'Nutrient', 'Veg_Non', 'description', 'Price', 'Review']]'''\n",
    "    def content_based_recommendation(self, user_id, top_n=10):\n",
    "        user_profile = self.profile[self.profile['User_Id'] == user_id]\n",
    "        user_features = user_profile['Nutrient'].values[0] + ' ' + user_profile['Disease'].values[0] + ' ' + user_profile['Diet'].values[0]\n",
    "        user_tfidf_matrix = self.tfidf.transform([user_features])\n",
    "        cosine_sim = linear_kernel(user_tfidf_matrix, self.tfidf_matrix).flatten()\n",
    "        \n",
    "        # Initialize a set to track unique Meal_Id recommendations\n",
    "        unique_meals = set()\n",
    "        recommendations = []\n",
    "        meal_indices = cosine_sim.argsort()[::-1]  # Sort indices in descending order of similarity\n",
    "        \n",
    "        for idx in meal_indices:\n",
    "            meal_id = self.df.at[idx, 'Meal_Id']\n",
    "            if meal_id not in unique_meals:\n",
    "                recommendations.append(self.df.iloc[idx])\n",
    "                unique_meals.add(meal_id)\n",
    "                if len(recommendations) == top_n:\n",
    "                    break\n",
    "        \n",
    "        recommendations = pd.DataFrame(recommendations)\n",
    "        del recommendations['combined_features']\n",
    "        return recommendations[['Meal_Id', 'Name', 'Nutrient', 'Veg_Non', 'description', 'Price']]\n",
    "\n",
    "# Usage\n",
    "print()\n",
    "print(\"Content Based Recommendation:\")\n",
    "user_id = 'User_44'\n",
    "ob = ContentBasedRecommender(dataset, profiles)\n",
    "result = ob.content_based_recommendation(user_id)\n",
    "print(result)\n",
    "\n",
    "\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "class SVDRecommender:\n",
    "    def __init__(self, profiles, recent_activity, dataset):\n",
    "        self.df = dataset\n",
    "        self.profiles = profiles\n",
    "        self.recent_activity = recent_activity\n",
    "        self.data = self.prepare_data()\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        # Create a Surprise Dataset\n",
    "        reader = Reader(rating_scale=(1, 5))  # Assuming a rating scale\n",
    "        data = Dataset.load_from_df(self.recent_activity[['User_Id', 'Meal_Id', 'Rated']], reader)\n",
    "        return data\n",
    "    \n",
    "    def svd_recommendation(self, user_id, top_n=10):\n",
    "        trainset = self.data.build_full_trainset()  # Use full data for training\n",
    "\n",
    "        # Define and train the model (SVD)\n",
    "        model = SVD()\n",
    "        model.fit(trainset)\n",
    "\n",
    "        # Get all meal IDs\n",
    "        all_meals = self.df['Meal_Id'].unique()\n",
    "\n",
    "        # Get the meals that the user hasn't interacted with\n",
    "        user_meals = self.recent_activity[self.recent_activity['User_Id'] == user_id]['Meal_Id']\n",
    "        unseen_meals = np.setdiff1d(all_meals, user_meals)\n",
    "\n",
    "        # Predict ratings for the unseen meals\n",
    "        predictions = [model.predict(user_id, meal_id) for meal_id in unseen_meals]\n",
    "\n",
    "        # Sort predictions by estimated ratings in descending order\n",
    "        sorted_predictions = sorted(predictions, key=lambda x: x.est, reverse=True)\n",
    "\n",
    "        # Get top N recommendations\n",
    "        top_recommendations = sorted_predictions[:top_n]\n",
    "\n",
    "        # Format and return top recommendations\n",
    "        top_meal_ids = [pred.iid for pred in top_recommendations]\n",
    "        recommended_meals = self.df[self.df['Meal_Id'].isin(top_meal_ids)]\n",
    "        recommended_meals = recommended_meals.drop_duplicates(subset=['Meal_Id'])\n",
    "        return recommended_meals[['Meal_Id', 'Name', 'Nutrient', 'Veg_Non', 'description', 'Price']]\n",
    "\n",
    "# Usage\n",
    "print()\n",
    "print(\"SVD Recommender:\")\n",
    "user_id = 'User_44'  # User ID of current user\n",
    "\n",
    "profiles = pd.read_csv('../Data processing/user_Profiles.csv')  # Profiles of all users\n",
    "recent_activity = pd.read_csv('../Data processing/recent_activity.csv')  # Recent activities of current user\n",
    "dataset = pd.read_csv('../Data processing/dataset.csv')  # Main dataset\n",
    "\n",
    "svd_ob = SVDRecommender(profiles, recent_activity, dataset)\n",
    "svd_result = svd_ob.svd_recommendation(user_id)\n",
    "print(svd_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
